{
  "deployment_basic": {
    "type": "template",
    "category": "deployment",
    "keywords": [
      "deployment",
      "create",
      "app",
      "container"
    ],
    "content": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{name}}\n  namespace: {{namespace}}\n  labels:\n    app: {{name}}\n    managed-by: ai4k8s\nspec:\n  replicas: {{replicas}}\n  selector:\n    matchLabels:\n      app: {{name}}\n  template:\n    metadata:\n      labels:\n        app: {{name}}\n    spec:\n      containers:\n      - name: {{name}}\n        image: {{image}}\n        ports:\n        - containerPort: {{port}}\n          name: http\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: {{port}}\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: {{port}}\n          initialDelaySeconds: 5\n          periodSeconds: 5",
    "description": "Production-ready deployment with health probes and resource limits",
    "best_practices": [
      "Always define resource requests and limits",
      "Include liveness and readiness probes",
      "Use meaningful labels",
      "Set initialDelaySeconds appropriately"
    ]
  },
  "service_clusterip": {
    "type": "template",
    "category": "service",
    "keywords": [
      "service",
      "expose",
      "internal",
      "clusterip"
    ],
    "content": "apiVersion: v1\nkind: Service\nmetadata:\n  name: {{name}}\n  namespace: {{namespace}}\n  labels:\n    app: {{name}}\nspec:\n  type: ClusterIP\n  selector:\n    app: {{name}}\n  ports:\n  - port: {{port}}\n    targetPort: {{target_port}}\n    protocol: TCP\n    name: http",
    "description": "Internal service for cluster-only access",
    "best_practices": [
      "ClusterIP for internal services",
      "LoadBalancer for external access",
      "Use consistent naming"
    ]
  },
  "hpa_standard": {
    "type": "template",
    "category": "autoscaling",
    "keywords": [
      "autoscale",
      "hpa",
      "scale",
      "horizontal"
    ],
    "content": "apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: {{name}}-hpa\n  namespace: {{namespace}}\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: {{name}}\n  minReplicas: {{min_replicas}}\n  maxReplicas: {{max_replicas}}\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 15\n    scaleUp:\n      stabilizationWindowSeconds: 0\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 15\n      - type: Pods\n        value: 4\n        periodSeconds: 15\n      selectPolicy: Max",
    "description": "Horizontal Pod Autoscaler with CPU and memory metrics",
    "best_practices": [
      "Set stabilization windows to prevent flapping",
      "Use conservative scaleDown (300s)",
      "Aggressive scaleUp (0s) for responsiveness",
      "Monitor metrics server availability"
    ]
  },
  "resources_practice": {
    "type": "best_practice",
    "category": "resources",
    "keywords": [
      "resources",
      "cpu",
      "memory",
      "limits",
      "requests"
    ],
    "content": "Resource Management Best Practices:\n\n1. Always define requests and limits:\n   - requests: Guaranteed resources (scheduling)\n   - limits: Maximum allowed (prevent noisy neighbors)\n\n2. CPU:\n   - request = expected average usage\n   - limit = burst capacity (2-3x request)\n   - CPU is throttled, not OOM\n\n3. Memory:\n   - request = limit (avoid OOM kills)\n   - Memory cannot be throttled\n   - OOM = pod killed\n\n4. Example:\n   resources:\n     requests:\n       cpu: 100m      # 0.1 CPU core\n       memory: 128Mi\n     limits:\n       cpu: 500m      # 0.5 CPU core burst\n       memory: 128Mi  # Same as request",
    "description": "How to properly set resource requests and limits"
  },
  "probes_practice": {
    "type": "best_practice",
    "category": "health",
    "keywords": [
      "probe",
      "health",
      "liveness",
      "readiness",
      "startup"
    ],
    "content": "Health Probes Best Practices:\n\n1. Liveness Probe:\n   - Checks if pod is alive\n   - Failed = restart pod\n   - Use for deadlock detection\n   - initialDelaySeconds: 30-60s\n\n2. Readiness Probe:\n   - Checks if pod can serve traffic\n   - Failed = remove from service\n   - Use for dependency checks\n   - initialDelaySeconds: 5-10s\n\n3. Startup Probe:\n   - For slow-starting containers\n   - Disables other probes until succeeds\n   - initialDelaySeconds: 0\n   - failureThreshold: 30\n\n4. Example:\n   livenessProbe:\n     httpGet:\n       path: /healthz\n       port: 8080\n     initialDelaySeconds: 30\n   readinessProbe:\n     httpGet:\n       path: /ready\n       port: 8080\n     initialDelaySeconds: 5",
    "description": "How to properly configure health probes"
  },
  "autoscaling_practice": {
    "type": "best_practice",
    "category": "autoscaling",
    "keywords": [
      "autoscaling",
      "hpa",
      "scaling",
      "metrics"
    ],
    "content": "Autoscaling Best Practices:\n\n1. HPA Metrics:\n   - CPU: Good for compute-bound apps\n   - Memory: Good for memory-bound apps\n   - Custom: Use for application-specific metrics\n\n2. Scaling Behavior:\n   - scaleDown stabilization: 300s (prevent flapping)\n   - scaleUp stabilization: 0s (fast response)\n   - Use policies to control rate\n\n3. Replica Settings:\n   - minReplicas: At least 2 for HA\n   - maxReplicas: Based on cluster capacity\n   - Target: 70-80% utilization\n\n4. Common Issues:\n   - Missing metrics server\n   - No resource requests defined\n   - Too aggressive thresholds\n   - Insufficient stabilization",
    "description": "How to properly configure autoscaling"
  },
  "security_practice": {
    "type": "best_practice",
    "category": "security",
    "keywords": [
      "security",
      "securitycontext",
      "privileged",
      "root"
    ],
    "content": "Security Best Practices:\n\n1. Never run as root:\n   securityContext:\n     runAsNonRoot: true\n     runAsUser: 1000\n     fsGroup: 1000\n\n2. Drop capabilities:\n   securityContext:\n     capabilities:\n       drop:\n       - ALL\n\n3. Read-only filesystem:\n   securityContext:\n     readOnlyRootFilesystem: true\n\n4. No privileged:\n   securityContext:\n     privileged: false\n     allowPrivilegeEscalation: false\n\n5. Network policies for isolation\n6. Use secrets for sensitive data\n7. Enable RBAC",
    "description": "Security hardening for Kubernetes pods"
  },
  "monitoring_cpu_optimization": {
    "type": "monitoring_guidance",
    "category": "monitoring",
    "keywords": [
      "cpu",
      "optimization",
      "scaling",
      "performance"
    ],
    "content": "CPU Monitoring and Optimization:\n\n1. CPU Usage Thresholds:\n   - < 30%: Underutilized - consider scaling down to save costs\n   - 30-70%: Healthy range - optimal performance\n   - 70-80%: Warning - monitor closely, prepare to scale\n   - > 80%: Critical - scale immediately or risk performance issues\n\n2. Scaling Strategies:\n   - Horizontal: Add more pods (recommended for stateless apps)\n   - Vertical: Increase CPU limits (for stateful apps)\n   - Auto-scaling: Use HPA with CPU metrics\n\n3. Cost Optimization:\n   - CPU < 30% consistently: Scale down by 30-50%\n   - CPU spikes: Check for resource limits, not just usage\n   - Burst capacity: Set limits 2-3x requests\n\n4. Common Issues:\n   - CPU throttling: Increase limits\n   - Uneven distribution: Check node affinity\n   - Memory pressure: Can cause CPU issues",
    "description": "CPU monitoring and optimization strategies"
  },
  "monitoring_memory_management": {
    "type": "monitoring_guidance",
    "category": "monitoring",
    "keywords": [
      "memory",
      "oom",
      "leaks",
      "optimization"
    ],
    "content": "Memory Monitoring and Management:\n\n1. Memory Usage Thresholds:\n   - < 50%: Healthy - good headroom\n   - 50-80%: Warning - monitor for trends\n   - 80-90%: Critical - high risk of OOM kills\n   - > 90%: Emergency - immediate action required\n\n2. Memory Issues:\n   - OOM Kills: Pod killed due to memory limit exceeded\n   - Memory Leaks: Gradual increase over time\n   - Swap Usage: Indicates memory pressure\n\n3. Optimization Strategies:\n   - Set memory requests = limits (prevent OOM)\n   - Monitor restart counts (indicates memory issues)\n   - Use memory profiling tools\n   - Check for memory leaks in applications\n\n4. Scaling Decisions:\n   - Memory > 80%: Scale up or optimize code\n   - Memory < 30%: Consider scaling down\n   - Uneven usage: Check resource distribution",
    "description": "Memory monitoring and optimization strategies"
  },
  "monitoring_pod_health": {
    "type": "monitoring_guidance",
    "category": "monitoring",
    "keywords": [
      "pods",
      "health",
      "restarts",
      "status"
    ],
    "content": "Pod Health Monitoring:\n\n1. Pod Status Indicators:\n   - Running: Healthy and ready\n   - Pending: Waiting for resources or scheduling\n   - Failed: Pod failed to start or crashed\n   - Unknown: Status unclear\n\n2. Restart Analysis:\n   - 0-2 restarts: Normal (startup issues)\n   - 3-10 restarts: Warning (application issues)\n   - > 10 restarts: Critical (configuration or code issues)\n\n3. Health Checks:\n   - Liveness Probe: Pod alive (failed = restart)\n   - Readiness Probe: Pod ready (failed = remove from service)\n   - Startup Probe: Initial startup (for slow apps)\n\n4. Troubleshooting:\n   - Check pod logs: kubectl logs <pod-name>\n   - Describe pod: kubectl describe pod <pod-name>\n   - Check events: kubectl get events\n   - Verify resource limits and requests",
    "description": "Pod health monitoring and troubleshooting"
  },
  "monitoring_scaling_recommendations": {
    "type": "monitoring_guidance",
    "category": "monitoring",
    "keywords": [
      "scaling",
      "recommendations",
      "hpa",
      "autoscaling"
    ],
    "content": "Intelligent Scaling Recommendations:\n\n1. CPU-Based Scaling:\n   - CPU > 80% for 5+ minutes: Scale up by 50%\n   - CPU < 30% for 10+ minutes: Scale down by 30%\n   - CPU spikes: Investigate before scaling\n\n2. Memory-Based Scaling:\n   - Memory > 85%: Scale up immediately\n   - Memory < 40%: Consider scaling down\n   - Memory leaks: Fix code, don't just scale\n\n3. Pod Count Optimization:\n   - Too many pods: Resource fragmentation\n   - Too few pods: Single point of failure\n   - Optimal: 3-5 pods per service\n\n4. HPA Configuration:\n   - Target CPU: 70% (industry standard)\n   - Target Memory: 80% (higher than CPU)\n   - Scale up: Aggressive (0s stabilization)\n   - Scale down: Conservative (300s stabilization)\n\n5. Cost-Benefit Analysis:\n   - Scale up cost: More resources\n   - Scale down benefit: Cost savings\n   - Balance: Performance vs cost",
    "description": "Intelligent scaling recommendations based on metrics"
  },
  "monitoring_anomaly_detection": {
    "type": "monitoring_guidance",
    "category": "monitoring",
    "keywords": [
      "anomaly",
      "detection",
      "alerts",
      "patterns"
    ],
    "content": "Anomaly Detection and Alerting:\n\n1. Normal Patterns:\n   - CPU: Gradual changes, predictable cycles\n   - Memory: Steady usage, occasional spikes\n   - Pods: Stable count, occasional restarts\n\n2. Anomaly Indicators:\n   - Sudden CPU spikes: Possible attacks or bugs\n   - Memory leaks: Gradual increase over time\n   - Pod restart storms: Configuration issues\n   - Resource exhaustion: Scaling problems\n\n3. Alert Thresholds:\n   - CPU > 90% for 2 minutes: Critical\n   - Memory > 85% for 5 minutes: Warning\n   - Pod restarts > 5 in 10 minutes: Critical\n   - Resource requests > 80%: Warning\n\n4. Response Actions:\n   - Immediate: Scale up resources\n   - Short-term: Investigate root cause\n   - Long-term: Optimize application\n   - Preventive: Set up monitoring dashboards",
    "description": "Anomaly detection and alerting strategies"
  }
}